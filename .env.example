# Backend model config (OpenAI-compatible local endpoint)
LLM_BASE_URL=http://localhost:1234/v1
LLM_API_KEY=local-key
LLM_MODEL=local-model

EMBED_BASE_URL=http://localhost:1234/v1
EMBED_API_KEY=local-key
EMBED_MODEL=local-embedding

# Reranking model config (SiliconFlow or OpenAI-compatible)
# SiliconFlow rerank models: https://docs.siliconflow.cn/reference/rerank
RERANK_BASE_URL=https://api.siliconflow.cn/v1
RERANK_API_KEY=${LLM_API_KEY}
RERANK_MODEL=BAAI/bge-reranker-v2-m3
RERANK_TOP_K=10

# Data storage paths
DATA_DIR=./data
DB_PATH=./data/app.db
INDEX_DIR=./data/index

# RAG settings
MAX_CONTEXT_CHUNKS=6
CHUNK_SIZE=512
CHUNK_OVERLAP=64
REQUIRE_CITATIONS=1
MIN_CITATIONS=1

# Semantic cache settings
ENABLE_SEMANTIC_CACHE=1
CACHE_SIMILARITY_THRESHOLD=0.95
CACHE_MAX_SIZE=1000
CACHE_TTL_HOURS=24

# Hybrid search settings
ENABLE_HYBRID_SEARCH=1
BM25_WEIGHT=0.3
VECTOR_WEIGHT=0.7
RETRIEVAL_MAX_REWRITES=4
RETRIEVAL_CANDIDATE_MULTIPLIER=3
RETRIEVAL_MAX_CHUNKS_PER_SOURCE=2
RETRIEVAL_DIVERSITY_PENALTY=0.28
RETRIEVAL_SOURCE_PENALTY=0.10
RETRIEVAL_MIN_CONTEXT_SCORE=0.08
RETRIEVAL_MIN_ANCHOR_COVERAGE=0.45
RETRIEVAL_MIN_FOCUS_COVERAGE=0.34
RETRIEVAL_MAX_CANDIDATES=180

# Multi-turn conversation settings
ENABLE_MULTI_TURN=1
MAX_CHAT_HISTORY=3

# Development settings
MOCK_MODE=0
USE_ENV_PROXY=1
