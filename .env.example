# Backend model config (OpenAI-compatible local endpoint)
LLM_BASE_URL=http://localhost:1234/v1
LLM_API_KEY=local-key
LLM_MODEL=local-model

EMBED_BASE_URL=http://localhost:1234/v1
EMBED_API_KEY=local-key
EMBED_MODEL=local-embedding

# Reranking model config (SiliconFlow or OpenAI-compatible)
# SiliconFlow rerank models: https://docs.siliconflow.cn/reference/rerank
RERANK_BASE_URL=https://api.siliconflow.cn/v1
RERANK_API_KEY=${LLM_API_KEY}
RERANK_MODEL=BAAI/bge-reranker-v2-m3
RERANK_TOP_K=10

# Data storage paths
DATA_DIR=./data
DB_PATH=./data/app.db
INDEX_DIR=./data/index

# RAG settings
MAX_CONTEXT_CHUNKS=6
CHUNK_SIZE=512
CHUNK_OVERLAP=64
REQUIRE_CITATIONS=1
MIN_CITATIONS=1

# Semantic cache settings
ENABLE_SEMANTIC_CACHE=1
CACHE_SIMILARITY_THRESHOLD=0.95
CACHE_MAX_SIZE=1000
CACHE_TTL_HOURS=24

# Hybrid search settings
ENABLE_HYBRID_SEARCH=1
BM25_WEIGHT=0.3
VECTOR_WEIGHT=0.7

# Multi-turn conversation settings
ENABLE_MULTI_TURN=1
MAX_CHAT_HISTORY=3

# Development settings
MOCK_MODE=0
USE_ENV_PROXY=1
